{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable magnitude\n",
    "\n",
    "### Does the magnitude of the variable matter?\n",
    "\n",
    "In Linear Regression models, the scale of variables used to estimate the output matters. Linear models are of the type **y = w x + b**, where the regression coefficient w represents the expected change in y for a one unit change in x (the predictor). Thus, the magnitude of w is partly determined by the magnitude of the units being used for x. If x is a distance variable, just changing the scale from kilometers to miles will cause a change in the magnitude of the coefficient.\n",
    "\n",
    "In addition, in situations where we estimate the outcome y by contemplating multiple predictors x1, x2, ...xn, predictors with greater numeric ranges dominate over those with smaller numeric ranges.\n",
    "\n",
    "Gradient descent converges faster when all the predictors (x1 to xn) are within a similar scale, therefore having features in a similar scale is useful for Neural Networks as well as.\n",
    "\n",
    "In Support Vector Machines, feature scaling can decrease the time to find the support vectors.\n",
    "\n",
    "Finally, methods using Euclidean distances or distances in general are also affected by the magnitude of the features, as Euclidean distance is sensitive to variations in the magnitude or scales of the predictors. Therefore feature scaling is required for methods that utilise distance calculations like k-nearest neighbours (KNN) and k-means clustering.\n",
    "\n",
    "In summary:\n",
    "\n",
    "#### Magnitude matters because:\n",
    "\n",
    "- The regression coefficient is directly influenced by the scale of the variable\n",
    "- Variables with bigger magnitude / value range dominate over the ones with smaller magnitude / value range\n",
    "- Gradient descent converges faster when features are on similar scales\n",
    "- Feature scaling helps decrease the time to find support vectors for SVMs\n",
    "- Euclidean distances are sensitive to feature magnitude.\n",
    "\n",
    "#### The machine learning models affected by the magnitude of the feature are:\n",
    "\n",
    "- Linear and Logistic Regression\n",
    "- Neural Networks\n",
    "- Support Vector Machines\n",
    "- KNN\n",
    "- K-means clustering\n",
    "- Linear Discriminant Analysis (LDA)\n",
    "- Principal Component Analysis (PCA)\n",
    "\n",
    "#### Machine learning models insensitive to feature magnitude are the ones based on Trees:\n",
    "\n",
    "- Classification and Regression Trees\n",
    "- Random Forests\n",
    "- Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature scaling with sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a real estate dataset. \n",
    "\n",
    "Real estate is one of those examples that every regression course goes through as it is extremely easy to understand and there is a (almost always) certain causal relationship to be found.\n",
    "\n",
    "## Standard Scaler\n",
    "\n",
    "Sklearn its main scaler, the StandardScaler, uses a strict definition of standardization to standardize data. It purely centers the data by using the following formula, where u is the mean and s is the standard deviation.\n",
    "x_scaled = (x â€” u) / s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# to scale the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# to evaluate performance and separate into\n",
    "# train and test set\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>234314.144</td>\n",
       "      <td>643.09</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228581.528</td>\n",
       "      <td>656.22</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>281626.336</td>\n",
       "      <td>487.29</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>401255.608</td>\n",
       "      <td>1504.75</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>458674.256</td>\n",
       "      <td>1275.46</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        price     size  year\n",
       "0  234314.144   643.09  2015\n",
       "1  228581.528   656.22  2009\n",
       "2  281626.336   487.29  2018\n",
       "3  401255.608  1504.75  2015\n",
       "4  458674.256  1275.46  2009"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\gusal\\\\machine learning\\\\Feature engineering\\\\python code\\\\real_estate_price_size_year.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>292289.470160</td>\n",
       "      <td>853.024200</td>\n",
       "      <td>2012.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>77051.727525</td>\n",
       "      <td>297.941951</td>\n",
       "      <td>4.729021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>154282.128000</td>\n",
       "      <td>479.750000</td>\n",
       "      <td>2006.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>234280.148000</td>\n",
       "      <td>643.330000</td>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>280590.716000</td>\n",
       "      <td>696.405000</td>\n",
       "      <td>2015.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>335723.696000</td>\n",
       "      <td>1029.322500</td>\n",
       "      <td>2018.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500681.128000</td>\n",
       "      <td>1842.510000</td>\n",
       "      <td>2018.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               price         size         year\n",
       "count     100.000000   100.000000   100.000000\n",
       "mean   292289.470160   853.024200  2012.600000\n",
       "std     77051.727525   297.941951     4.729021\n",
       "min    154282.128000   479.750000  2006.000000\n",
       "25%    234280.148000   643.330000  2009.000000\n",
       "50%    280590.716000   696.405000  2015.000000\n",
       "75%    335723.696000  1029.322500  2018.000000\n",
       "max    500681.128000  1842.510000  2018.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's have a look at the values of those variables\n",
    "# to get an idea of the feature magnitudes\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that size varies between 480 and 1843, year between 2006 and 2018. So the variables have different magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size range:  1362.76\n",
      "year range:  12\n"
     ]
    }
   ],
   "source": [
    "# let's now calculate the range\n",
    "\n",
    "for col in ['size', 'year']:\n",
    "    print(col, 'range: ', data[col].max() - data[col].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The range of values that each variable can take are quite different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare the dependent and the independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = data[['size','year']]\n",
    "y = data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70, 2), (30, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's separate into training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x,y,\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression on unscaled variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model build on unscaled variables\n",
    "# call the model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# train the model\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# evaluate performance\n",
    "\n",
    "pred_test = reg.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([234789.76598258, 196736.22379736, 216244.65467349, 442856.59794862,\n",
       "       260209.43470158, 263051.09589619, 261331.90196503, 225652.38478638,\n",
       "       247325.31989282, 216734.47400903, 251779.26768641, 257755.83584681,\n",
       "       246118.27118608, 332031.81135881, 228029.98997407, 314435.56779708,\n",
       "       371539.85431297, 211412.73692404, 220330.64770139, 259495.13735212,\n",
       "       390716.89984298, 371133.90271374, 437490.35182723, 233041.16299408,\n",
       "       258592.14050752, 244150.91148572, 230330.8105939 , 246768.0946664 ,\n",
       "       241395.33634217, 370677.07261666])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7808422782486512"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Adjusted R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the handy function we created\n",
    "def adj_r2(X_test,y_test):\n",
    "    r2 = reg.score(X_test,y_test)\n",
    "    n = X_test.shape[0]\n",
    "    p = X_test.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7646083729337364"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_adjusted = adj_r2(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2891242.2628917126"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 221.83147499, 1486.31846289])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cal the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# call the model\n",
    "reg_scaleding = LinearRegression()\n",
    "\n",
    "# fit the scaler\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  [-4.01266322e-16  2.07833750e-14]\n",
      "Standard Deviation:  [1. 1.]\n",
      "Minimum value:  [-1.23748987 -1.37274255]\n",
      "Maximum value:  [3.29596754 1.18971021]\n"
     ]
    }
   ],
   "source": [
    "#let's have a look at the scaled training dataset\n",
    "\n",
    "print('Mean: ', X_train_scaled.mean(axis=0))\n",
    "print('Standard Deviation: ', X_train_scaled.std(axis=0))\n",
    "print('Minimum value: ', X_train_scaled.min(axis=0))\n",
    "print('Maximum value: ', X_train_scaled.max(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression on scaled variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model build on scaled variables\n",
    "# call the model\n",
    "reg_scaled = LinearRegression()\n",
    "\n",
    "# train the model\n",
    "reg_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# evaluate performance\n",
    "\n",
    "pred_test_scaled = reg_scaled.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295040.45062857127"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reg_scaled.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64792.42758435,  6960.4489198 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reg_scaled.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7808422782486508"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_scaled.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Adjusted R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the handy function we created\n",
    "def adj_r2(X_test_scaled,y_test):\n",
    "    r2 = reg_scaled.score(X_test_scaled,y_test)\n",
    "    n = X_test_scaled.shape[0]\n",
    "    p = X_test_scaled.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adj_R2_scaled = adj_r2(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7646083729337361"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adj_R2_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the R-squared and the Adjusted R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the the R-squared is only slightly larger than the Adjusted R-squared, implying that we were not penalized a lot for the inclusion of 2 independent variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the Adjusted R-squared with the R-squared of the simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the Adjusted R-squared with the R-squared, we realize that 'Year' is not bringing too much value to the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions\n",
    "\n",
    "Find the predicted price of an apartment that has a size of 750 sq.ft. from 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = [[750,2009]]\n",
    "new_data_scaled = scaler.transform(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2892429.04139697])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict(new_data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a summary table with your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficients_scaled</th>\n",
       "      <th>Coefficients</th>\n",
       "      <th>R2_adjusted_scaled</th>\n",
       "      <th>R2_adjusted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>size</td>\n",
       "      <td>64792.427584</td>\n",
       "      <td>221.831475</td>\n",
       "      <td>0.764608</td>\n",
       "      <td>0.764608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>year</td>\n",
       "      <td>6960.448920</td>\n",
       "      <td>1486.318463</td>\n",
       "      <td>0.764608</td>\n",
       "      <td>0.764608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Features  Coefficients_scaled  Coefficients  R2_adjusted_scaled  R2_adjusted\n",
       "0     size         64792.427584    221.831475            0.764608     0.764608\n",
       "1     year          6960.448920   1486.318463            0.764608     0.764608"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_summary = pd.DataFrame(data = x.columns.values, columns=['Features'])\n",
    "reg_summary ['Coefficients_scaled'] = reg_scaled.coef_\n",
    "reg_summary ['Coefficients'] = reg.coef_\n",
    "reg_summary ['R2_adjusted_scaled'] = Adj_R2_scaled\n",
    "reg_summary ['R2_adjusted'] = Adj_R2\n",
    "reg_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the performance of linear regression did not change when using the datasets with the features scaled (compare R2_adj values for train and test set for models with and without feature scaling). \n",
    "\n",
    "However, when looking at the coefficients we do see a big difference in the values. This is because the magnitude of the variable was affecting the coefficients. After scaling, all 3 variables have the relatively the same effect (coefficient) towards price."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
